{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import xavier_initializer\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('datasets/data_classifier_train.npz')\n",
    "test_data = np.load('datasets/data_classifier_test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(train_data['x_train'], dtype=np.float32) / 255\n",
    "y_train = np.asarray(train_data['y_train'], dtype=np.int32)\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "\n",
    "X_test = np.asarray(test_data['x_test'], dtype=np.float32) / 255\n",
    "y_test = np.asarray(test_data['y_test'], dtype=np.int32)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=1)\n",
    "NUM_LABELS = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode, params):\n",
    "    if params == None:\n",
    "        learning_rate = 0.001\n",
    "        momentum = 0.9\n",
    "    else:\n",
    "        learning_rate = params['learning_rate']\n",
    "        momentum = params['momentum']\n",
    "    input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "    conv_layers = [\n",
    "        [32, 3, 1],\n",
    "        [32, 5, 2],\n",
    "        [64, 3, 1],\n",
    "        [64, 5, 2]\n",
    "    ]\n",
    "    curr_layer = input_layer\n",
    "    for i, [f, k, s] in enumerate(conv_layers, start=1):\n",
    "        curr_layer = tf.layers.conv2d(\n",
    "            inputs=curr_layer,\n",
    "            filters=f,\n",
    "            kernel_size=k,\n",
    "            strides=s,\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=xavier_initializer(seed=i),\n",
    "            name=f'conv{i}'\n",
    "        )\n",
    "    conv_flat = tf.reshape(curr_layer, [-1, np.prod(curr_layer.shape[1:])])\n",
    "    dense = tf.layers.dense(\n",
    "        inputs=conv_flat,\n",
    "        units=1024,\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "    logits = tf.layers.dense(\n",
    "        inputs=dense,\n",
    "        units=NUM_LABELS\n",
    "    )\n",
    "    predictions = {\n",
    "        'classes': tf.argmax(input=logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        # ================== my momentum optimizer ===============\n",
    "        xs = tf.trainable_variables()\n",
    "        prev_deltas = [\n",
    "            tf.Variable(initial_value=tf.zeros(shape=x.shape, dtype=x.dtype), trainable=False)\n",
    "            for x in xs\n",
    "        ]\n",
    "        grads = tf.gradients(loss, xs)\n",
    "        train_ops = []\n",
    "        for x, grad, prev_delta in zip(xs, grads, prev_deltas):\n",
    "            curr_delta = momentum * prev_delta - learning_rate * grad\n",
    "            train_ops.append(tf.assign_add(x, curr_delta))\n",
    "            train_ops.append(tf.assign(prev_delta, curr_delta))\n",
    "        global_step = tf.train.get_global_step()\n",
    "        train_ops.append(tf.assign_add(global_step, tf.constant(1, dtype=global_step.dtype)))\n",
    "        train_op = tf.group(train_ops)\n",
    "        # ==============================================================\n",
    "        # tensorflow momentum optimizer\n",
    "#         optimizer = tf.train.MomentumOptimizer(momentum=momentum, learning_rate=learning_rate)\n",
    "#         train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(\n",
    "            labels=labels,\n",
    "            predictions=predictions['classes'])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cnn(X_train, y_train, X_eval, y_eval,\n",
    "                   learning_rate, momentum, batch_size=64, steps=10000):\n",
    "    model_dir = f'cnn_model_{momentum}_{learning_rate}'\n",
    "    # remove old models\n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'momentum': momentum\n",
    "    }\n",
    "    mnist_classifier = tf.estimator.Estimator(\n",
    "        model_fn=cnn_model_fn,\n",
    "        model_dir=model_dir,\n",
    "        params=params)\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'x': X_train},\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=None,\n",
    "        shuffle=False)\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'x': X_eval},\n",
    "        y=y_eval,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    trainset_eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'x': X_train},\n",
    "        y=y_train,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    start_ts = time.time()\n",
    "    mnist_classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=steps)\n",
    "    end_ts = time.time()\n",
    "    trainset_score = mnist_classifier.evaluate(input_fn=trainset_eval_input_fn)\n",
    "    eval_score = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(f'Training time in seconds: {end_ts - start_ts}')\n",
    "    print('Performance on training set: ')\n",
    "    print(trainset_score)\n",
    "    print('Performance on validation/test set: ')\n",
    "    print(eval_score)\n",
    "    return mnist_classifier, eval_score['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_cv(X, y, n_splits, momentums, learning_rates):\n",
    "    for momentum in momentums:\n",
    "        for learning_rate in learning_rates:\n",
    "            accuracy = []\n",
    "            for _ in range(0, n_splits):\n",
    "                X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2)\n",
    "                clf, accu = train_eval_cnn(X_train, y_train, X_eval, y_eval, learning_rate, momentum)\n",
    "                accuracy.append(accu)\n",
    "            print(f'Momentum = {momentum}, Learning rate = {learning_rate}, Average accuracy: {np.mean(accuracy)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross validation to find optimal momentum\n",
    "momentums = np.arange(0.5, 1, 0.1)\n",
    "learning_rates = [0.001]\n",
    "cnn_cv(X_train, y_train, 5, momentums, learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross validation to find optimal learning rate\n",
    "momentums = [0.9]\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "cnn_cv(X_train, y_train, 5, momentums, learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train final model using the optimal momentum and learning rate\n",
    "# the accuracy and loss on both the training and test sets are printed\n",
    "train_eval_cnn(X_train, y_train, X_test, y_test, learning_rate=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
